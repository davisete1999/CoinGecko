#!/usr/bin/env python3
"""
Script para descargar datos de criptomonedas en rangos de d√≠as desde CoinGecko usando Selenium
Usa el esquema normalizado de PostgreSQL con tablas separadas por fuente y guarda en InfluxDB
Con tracking de √∫ltima fecha procesada para continuar desde donde se qued√≥

VERSI√ìN FINAL NORMALIZADA:
- Esquema normalizado con separaci√≥n por fuentes
- Manejo robusto de valores None en conversiones num√©ricas
- Identificaci√≥n √∫nica por crypto_id para evitar duplicados
- Validaciones mejoradas de datos de entrada
- Logs detallados y tracking completo de progreso
- Compatible con estructura actual de crypto_scraping_log
"""

import json
import os
import time
import random
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

import influxdb_client
from influxdb_client import Point
from influxdb_client.client.write_api import SYNCHRONOUS

import psycopg2
from psycopg2.extras import RealDictCursor

# Configurar logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('coingecko_range_scraper.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def load_env_file(env_file: str = '.env'):
    """Cargar variables de entorno desde archivo .env"""
    env_vars_loaded = 0
    try:
        with open(env_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    
                    os.environ[key] = value
                    env_vars_loaded += 1
                    logger.debug(f"Cargada variable: {key}")
        
        logger.info(f"‚úÖ {env_vars_loaded} variables de entorno cargadas desde {env_file}")
            
    except FileNotFoundError:
        logger.warning(f"‚ö†Ô∏è Archivo {env_file} no encontrado, usando variables de entorno del sistema")
    except Exception as e:
        logger.error(f"‚ùå Error cargando {env_file}: {e}")

@dataclass
class InfluxDBConfig:
    """Configuraci√≥n de InfluxDB desde variables de entorno"""
    host: str = os.getenv('INFLUXDB_HOST', 'localhost')
    port: int = int(os.getenv('INFLUXDB_EXTERNAL_PORT') or '8086')  # ARREGLADO: Manejar None
    database: str = os.getenv('INFLUXDB_DB', 'crypto_historical')
    token: str = os.getenv('INFLUXDB_TOKEN', '0_aEXpz0v0Nhbw-fHpaarS4IEcrktOJjSGFpG9SLMh3tijC8QDyI9ahXfmNnBtQ1sSnIIlGMYqJCo3A6rtF9NQ==')
    org: str = os.getenv('INFLUXDB_ORG', 'CoinAdvisor')
    
    def __post_init__(self):
        """Validar configuraci√≥n despu√©s de inicializaci√≥n"""
        if not self.token:
            logger.error("‚ùå INFLUXDB_TOKEN est√° vac√≠o")
            raise ValueError("INFLUXDB_TOKEN is required for InfluxDB v2")
        
        if not self.org:
            logger.error("‚ùå INFLUXDB_ORG est√° vac√≠o")
            raise ValueError("INFLUXDB_ORG is required for InfluxDB v2")
        
        logger.info(f"üîß InfluxDB Config: {self.host}:{self.port} | org='{self.org}', bucket='{self.database}'")

@dataclass
class PostgreSQLConfig:
    """Configuraci√≥n de PostgreSQL desde variables de entorno"""
    host: str = os.getenv('POSTGRES_HOST', 'localhost')
    port: int = int(os.getenv('POSTGRES_EXTERNAL_PORT') or '5432')  # ARREGLADO: Manejar None
    database: str = os.getenv('POSTGRES_DB', 'cryptodb')
    user: str = os.getenv('POSTGRES_USER', 'crypto_user')
    password: str = os.getenv('POSTGRES_PASSWORD', 'davisete453')
    
    def __post_init__(self):
        """Validar configuraci√≥n despu√©s de inicializaci√≥n"""
        logger.info(f"üîß PostgreSQL Config: {self.host}:{self.port}/{self.database}")

class PostgreSQLManager:
    """Manejador de PostgreSQL con esquema normalizado para rangos CoinGecko"""
    
    def __init__(self, config: PostgreSQLConfig):
        self.config = config
        self.connection = None
        self.coingecko_source_id = None
        
    def connect(self):
        """Conectar a PostgreSQL y obtener ID de fuente CoinGecko"""
        try:
            self.connection = psycopg2.connect(
                host=self.config.host,
                port=self.config.port,
                database=self.config.database,
                user=self.config.user,
                password=self.config.password,
                cursor_factory=RealDictCursor
            )
            
            # Obtener ID de fuente CoinGecko
            with self.connection.cursor() as cursor:
                cursor.execute("SELECT id FROM crypto_sources WHERE source_name = 'coingecko'")
                result = cursor.fetchone()
                if result:
                    self.coingecko_source_id = result['id']
                    logger.info(f"‚úÖ Conectado a PostgreSQL - CoinGecko source_id: {self.coingecko_source_id}")
                else:
                    logger.error("‚ùå No se encontr√≥ fuente 'coingecko' en crypto_sources")
                    return False
            
            return True
        except Exception as e:
            logger.error(f"‚ùå Error conectando a PostgreSQL: {e}")
            return False
    
    def get_coingecko_cryptocurrencies_for_ranges(self, limit: Optional[int] = None) -> List[Dict]:
        """Obtiene criptomonedas CoinGecko priorizadas para scraping por rangos"""
        if not self.connection:
            logger.error("‚ùå No hay conexi√≥n a PostgreSQL")
            return []
        
        try:
            with self.connection.cursor() as cursor:
                # Consulta usando esquema normalizado con priorizaci√≥n para rangos
                sql = """
                SELECT 
                    c.id as crypto_id,
                    c.name,
                    c.symbol,
                    c.slug,
                    c.is_active,
                    
                    -- Datos espec√≠ficos de CoinGecko
                    cg.id as coingecko_id,
                    cg.coingecko_rank,
                    cg.coingecko_url,
                    cg.icon_url,
                    cg.coin_url,
                    cg.tags,
                    cg.badges,
                    cg.last_values_update,
                    cg.oldest_data_fetched,
                    cg.scraping_status,
                    cg.total_data_points,
                    cg.last_fetch_attempt,
                    cg.fetch_error_count,
                    cg.next_fetch_priority,
                    cg.scraping_notes,
                    
                    -- Determinar categor√≠a de prioridad espec√≠fica para rangos
                    CASE 
                        WHEN cg.scraping_status = 'pending' THEN 'URGENT'
                        WHEN cg.scraping_status = 'error' AND cg.fetch_error_count < 3 THEN 'RETRY'
                        WHEN cg.scraping_status = 'in_progress' AND 
                             cg.last_fetch_attempt < NOW() - INTERVAL '2 hours' THEN 'STUCK'
                        WHEN cg.scraping_status = 'completed' AND 
                             (cg.last_values_update IS NULL OR 
                              cg.last_values_update < CURRENT_DATE - INTERVAL '30 days') THEN 'UPDATE_NEEDED'
                        WHEN cg.scraping_status = 'completed' THEN 'CURRENT'
                        ELSE 'UNKNOWN'
                    END as priority_category
                    
                FROM cryptos c
                INNER JOIN coingecko_cryptos cg ON c.id = cg.crypto_id
                WHERE c.is_active = true 
                AND c.slug IS NOT NULL 
                AND c.slug != ''
                ORDER BY 
                    -- Prioridad por categor√≠a espec√≠fica para rangos
                    CASE 
                        WHEN cg.scraping_status = 'pending' THEN 1
                        WHEN cg.scraping_status = 'in_progress' AND 
                             cg.last_fetch_attempt < NOW() - INTERVAL '2 hours' THEN 2
                        WHEN cg.scraping_status = 'error' AND cg.fetch_error_count < 3 THEN 3
                        WHEN cg.scraping_status = 'completed' AND 
                             (cg.last_values_update IS NULL OR 
                              cg.last_values_update < CURRENT_DATE - INTERVAL '30 days') THEN 4
                        WHEN cg.scraping_status = 'completed' THEN 5
                        ELSE 6
                    END,
                    -- Prioridad secundaria por sistema calculado
                    cg.next_fetch_priority ASC,
                    -- Prioridad terciaria por ranking CoinGecko
                    cg.coingecko_rank ASC NULLS LAST,
                    -- √öltima prioridad alfab√©tica
                    c.symbol ASC
                """
                
                if limit:
                    sql += f" LIMIT {limit}"
                
                cursor.execute(sql)
                rows = cursor.fetchall()
                
                # Convertir a formato compatible para ranges
                cryptocurrencies = []
                priority_stats = {'URGENT': 0, 'STUCK': 0, 'RETRY': 0, 'UPDATE_NEEDED': 0, 'CURRENT': 0, 'UNKNOWN': 0}
                
                for row in rows:
                    crypto = {
                        'crypto_id': row['crypto_id'],
                        'coingecko_id': row['coingecko_id'],
                        'nombre': row['name'],
                        'simbolo': row['symbol'],
                        'enlace': row['coin_url'] or f"https://www.coingecko.com/es/monedas/{row['slug']}",
                        'slug': row['slug'],
                        'coingecko_rank': row['coingecko_rank'],
                        'tags': row['tags'] or [],
                        'badges': row['badges'] or [],
                        'last_values_update': row['last_values_update'],
                        'oldest_data_fetched': row['oldest_data_fetched'],
                        'scraping_status': row['scraping_status'],
                        'total_data_points': row['total_data_points'] or 0,
                        'fetch_error_count': row['fetch_error_count'] or 0,
                        'priority_category': row['priority_category'],
                        'scraping_notes': row['scraping_notes']
                    }
                    cryptocurrencies.append(crypto)
                    
                    # Contar estad√≠sticas de prioridad
                    category = row['priority_category']
                    if category in priority_stats:
                        priority_stats[category] += 1
                
                logger.info(f"‚úÖ Obtenidas {len(cryptocurrencies)} criptomonedas CoinGecko para rangos")
                logger.info(f"üìä Distribuci√≥n por prioridad: {priority_stats}")
                
                return cryptocurrencies
                
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo criptomonedas CoinGecko para rangos: {e}")
            return []
    
    def update_coingecko_range_scraping_status(self, crypto_id: int = None, symbol: str = None, 
                                             name: str = None, status: str = 'in_progress', 
                                             last_date: str = None, total_points: int = 0, 
                                             notes: str = None):
        """
        Actualiza el estado de scraping por rangos en esquema normalizado
        ARREGLADO: Usa crypto_id directamente cuando est√° disponible para evitar duplicados
        """
        if not self.connection:
            return
        
        try:
            with self.connection.cursor() as cursor:
                update_fields = []
                params = []
                
                # Campos b√°sicos siempre actualizados
                update_fields.extend([
                    "scraping_status = %s",
                    "last_fetch_attempt = CURRENT_TIMESTAMP"
                ])
                params.extend([status])
                
                # Campos condicionales
                if last_date:
                    update_fields.append("last_values_update = %s")
                    params.append(last_date)
                
                if total_points > 0:
                    update_fields.append("total_data_points = COALESCE(total_data_points, 0) + %s")
                    params.append(total_points)
                
                if status == 'completed':
                    update_fields.append("fetch_error_count = 0")
                elif status == 'error':
                    update_fields.append("fetch_error_count = COALESCE(fetch_error_count, 0) + 1")
                
                if notes:
                    update_fields.append("scraping_notes = %s")
                    params.append(notes)
                
                # ARREGLADO: Usar crypto_id directamente cuando est√© disponible
                if crypto_id:
                    # Usar crypto_id directamente (m√©todo preferido)
                    params.append(crypto_id)
                    where_clause = "WHERE crypto_id = %s"
                    identifier = f"crypto_id={crypto_id}"
                    
                elif symbol and name:
                    # Usar combinaci√≥n de symbol y name para identificar √∫nicamente
                    params.extend([symbol, name])
                    where_clause = """
                        WHERE crypto_id = (
                            SELECT id FROM cryptos 
                            WHERE symbol = %s AND name = %s 
                            LIMIT 1
                        )
                    """
                    identifier = f"{symbol} ({name})"
                    
                elif symbol:
                    # Fallback: usar solo symbol pero con LIMIT 1 para evitar error
                    params.append(symbol)
                    where_clause = """
                        WHERE crypto_id = (
                            SELECT id FROM cryptos 
                            WHERE symbol = %s 
                            ORDER BY id 
                            LIMIT 1
                        )
                    """
                    identifier = f"{symbol} (por symbol - primer match)"
                    logger.warning(f"‚ö†Ô∏è Usando solo symbol para {symbol}, puede no ser √∫nico")
                    
                else:
                    logger.error("‚ùå No se proporcion√≥ crypto_id, symbol o name para identificar la crypto")
                    return
                
                sql = f"""
                    UPDATE coingecko_cryptos 
                    SET {', '.join(update_fields)}
                    {where_clause}
                """
                
                cursor.execute(sql, params)
                rows_affected = cursor.rowcount
                self.connection.commit()
                
                if rows_affected > 0:
                    logger.debug(f"‚úÖ Estado de rangos actualizado para {identifier}: {status}")
                else:
                    logger.warning(f"‚ö†Ô∏è No se encontr√≥ crypto para actualizar rangos: {identifier}")
                
        except Exception as e:
            logger.error(f"‚ùå Error actualizando estado de rangos: {e}")
            if self.connection:
                self.connection.rollback()
    
    def create_range_scraping_log_entry(self, crypto_id: int, success: bool, 
                                       start_date: str, end_date: str, data_points: int = 0, 
                                       error_message: str = None, duration_seconds: int = None):
        """Crea entrada en log de scraping para rangos usando esquema normalizado"""
        if not self.connection or not self.coingecko_source_id:
            return
        
        try:
            with self.connection.cursor() as cursor:
                # ARREGLADO: Removida columna scraping_type que no existe en la tabla
                cursor.execute("""
                    INSERT INTO crypto_scraping_log (
                        crypto_id, source_id, date_range_start, date_range_end,
                        data_points_fetched, fetch_duration_seconds, success, error_message
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    crypto_id, self.coingecko_source_id, start_date, end_date,
                    data_points, duration_seconds, success, error_message
                ))
                self.connection.commit()
                logger.debug(f"‚úÖ Log de scraping de rangos creado para crypto_id {crypto_id}")
                
        except Exception as e:
            logger.error(f"‚ùå Error creando log de scraping de rangos: {e}")
            if self.connection:
                self.connection.rollback()
    
    def get_coingecko_range_scraping_stats(self) -> Dict:
        """Obtiene estad√≠sticas de scraping de rangos CoinGecko"""
        if not self.connection:
            return {}
        
        try:
            with self.connection.cursor() as cursor:
                # Consulta directa sin depender de vistas
                cursor.execute("""
                    SELECT 
                        cg.scraping_status,
                        COUNT(*) as count,
                        SUM(cg.total_data_points) as total_points,
                        AVG(cg.fetch_error_count) as avg_errors,
                        COUNT(CASE WHEN cg.last_values_update IS NOT NULL THEN 1 END) as with_data
                    FROM cryptos c
                    JOIN coingecko_cryptos cg ON c.id = cg.crypto_id
                    WHERE c.is_active = true
                    GROUP BY cg.scraping_status
                    ORDER BY cg.scraping_status
                """)
                
                stats = {}
                for row in cursor.fetchall():
                    stats[row['scraping_status']] = {
                        'count': row['count'],
                        'total_points': row['total_points'] or 0,
                        'avg_errors': float(row['avg_errors'] or 0),
                        'with_data': row['with_data'] or 0
                    }
                
                return stats
                
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo estad√≠sticas de rangos CoinGecko: {e}")
            return {}
    
    def close(self):
        """Cerrar conexi√≥n a PostgreSQL"""
        if self.connection:
            self.connection.close()
            logger.info("üîê Conexi√≥n PostgreSQL cerrada")

class InfluxDBManager:
    """Manejador de InfluxDB para datos hist√≥ricos por rangos CoinGecko con validaciones robustas"""
    
    def __init__(self, config: InfluxDBConfig):
        self.config = config
        self.client = None
        self.write_api = None
        
    def connect(self):
        """Conectar a InfluxDB v2"""
        try:
            url = f"http://{self.config.host}:{self.config.port}"
            
            logger.info(f"üîÑ Conectando a InfluxDB v2: {url}")
            
            self.client = influxdb_client.InfluxDBClient(
                url=url,
                token=self.config.token,
                org=self.config.org
            )
            
            # Verificar conexi√≥n
            try:
                health = self.client.health()
                logger.info(f"‚úÖ InfluxDB Status: {health.status}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è No se pudo verificar estado de InfluxDB: {e}")
            
            # Configurar write API
            self.write_api = self.client.write_api(write_options=SYNCHRONOUS)
            logger.info("‚úÖ Conectado a InfluxDB v2")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error conectando a InfluxDB: {e}")
            return False
    
    def save_coingecko_range_data(self, crypto_data: Dict, start_date: str, end_date: str, 
                                 combined_data: List[Dict]) -> bool:
        """Guarda datos de rango CoinGecko en InfluxDB con tags espec√≠ficos y validaciones robustas"""
        if not combined_data or not self.write_api:
            logger.warning("‚ö†Ô∏è No hay datos o write_api no disponible")
            return False
        
        try:
            points = []
            
            symbol = crypto_data.get('simbolo', 'UNKNOWN')
            name = crypto_data.get('nombre', 'Unknown')
            slug = crypto_data.get('slug', '')
            coingecko_rank = crypto_data.get('coingecko_rank')
            
            logger.info(f"üîÑ Preparando {len(combined_data)} puntos para rango CoinGecko {start_date} ‚Üí {end_date}")
            
            for data_point in combined_data:
                try:
                    # ARREGLADO: Validar timestamp antes de conversi√≥n
                    timestamp_ms = data_point.get('timestamp')
                    if timestamp_ms is None:
                        logger.debug(f"‚ö†Ô∏è Timestamp None para {symbol}")
                        continue
                    
                    # Asegurar que timestamp_ms es num√©rico
                    try:
                        timestamp_ms = float(timestamp_ms)
                        if timestamp_ms <= 0:
                            continue
                    except (ValueError, TypeError):
                        logger.debug(f"‚ö†Ô∏è Timestamp no num√©rico para {symbol}: {timestamp_ms}")
                        continue
                    
                    # CoinGecko timestamps est√°n en milisegundos
                    timestamp_dt = datetime.fromtimestamp(timestamp_ms / 1000, tz=timezone.utc)
                    
                    price = data_point.get('price')
                    market_cap = data_point.get('market_cap')
                    
                    # Validar que tenemos al menos un dato v√°lido
                    if price is None and market_cap is None:
                        continue
                    
                    # Crear punto para InfluxDB con tags espec√≠ficos de rangos CoinGecko
                    point = Point("coingecko_historical_ranges")
                    point.tag("symbol", symbol)
                    point.tag("name", name)
                    point.tag("slug", slug)
                    point.tag("source", "coingecko_ranges_normalized")
                    point.tag("range_start", start_date)
                    point.tag("range_end", end_date)
                    
                    # ARREGLADO: Tags adicionales espec√≠ficos de CoinGecko con validaci√≥n
                    if coingecko_rank is not None:
                        try:
                            rank_int = int(float(coingecko_rank))  # Convertir v√≠a float para manejar strings
                            point.tag("rank_category", self._get_rank_category(rank_int))
                            point.field("coingecko_rank", rank_int)
                        except (ValueError, TypeError):
                            logger.debug(f"‚ö†Ô∏è Ranking inv√°lido para {symbol}: {coingecko_rank}")
                    
                    # ARREGLADO: Campos de datos con validaci√≥n mejorada
                    if price is not None:
                        try:
                            price_float = float(price)
                            if price_float >= 0:  # Permitir precio 0
                                point.field("price", price_float)
                        except (ValueError, TypeError):
                            logger.debug(f"‚ö†Ô∏è Precio inv√°lido para {symbol}: {price}")
                    
                    if market_cap is not None:
                        try:
                            market_cap_float = float(market_cap)
                            if market_cap_float >= 0:  # Permitir market cap 0
                                point.field("market_cap", market_cap_float)
                        except (ValueError, TypeError):
                            logger.debug(f"‚ö†Ô∏è Market cap inv√°lido para {symbol}: {market_cap}")
                    
                    # Campos calculados
                    point.field("data_quality_score", self._calculate_data_quality(price, market_cap))
                    
                    point.time(timestamp_dt)
                    points.append(point)
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error procesando punto de datos para {symbol}: {e}")
                    continue
            
            if points:
                logger.info(f"üîÑ Escribiendo {len(points)} puntos del rango CoinGecko a InfluxDB...")
                
                # Escribir en lotes para mejor rendimiento
                batch_size = 1000
                for i in range(0, len(points), batch_size):
                    batch = points[i:i + batch_size]
                    
                    self.write_api.write(
                        bucket=self.config.database,
                        org=self.config.org,
                        record=batch
                    )
                    
                    logger.debug(f"‚úÖ Lote {i//batch_size + 1} escrito ({len(batch)} puntos)")
                
                logger.info(f"‚úÖ Guardados {len(points)} puntos del rango {start_date} ‚Üí {end_date} en InfluxDB")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è No hay puntos v√°lidos para el rango {start_date} ‚Üí {end_date}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error guardando rango {start_date} ‚Üí {end_date}: {e}")
            return False
    
    def _get_rank_category(self, rank) -> str:
        """Categoriza el ranking de CoinGecko con validaci√≥n"""
        try:
            # ARREGLADO: Validar y convertir rank antes de usar
            if rank is None:
                return "unranked"
            
            rank_int = int(float(rank))
            
            if rank_int <= 10:
                return "top_10"
            elif rank_int <= 50:
                return "top_50"
            elif rank_int <= 100:
                return "top_100"
            elif rank_int <= 500:
                return "top_500"
            else:
                return "others"
        except (ValueError, TypeError):
            return "unranked"
    
    def _calculate_data_quality(self, price, market_cap) -> float:
        """Calcula un score de calidad de datos con validaci√≥n"""
        score = 0.0
        
        # ARREGLADO: Validar valores antes de usar
        try:
            if price is not None and float(price) > 0:
                score += 0.5
        except (ValueError, TypeError):
            pass
        
        try:
            if market_cap is not None and float(market_cap) > 0:
                score += 0.5
        except (ValueError, TypeError):
            pass
        
        return score
    
    def close(self):
        """Cerrar conexi√≥n a InfluxDB"""
        if self.client:
            self.client.close()
            logger.info("üîê Conexi√≥n InfluxDB cerrada")

class SeleniumRangeCryptoDataScraper:
    def __init__(self, 
                 values_dir: str = "values",
                 daily_dir: str = "daily_data", 
                 delay: float = 2.0,
                 headless: bool = True,
                 range_days: int = 30,
                 crypto_limit: Optional[int] = None,
                 influxdb_config: InfluxDBConfig = None,
                 postgres_config: PostgreSQLConfig = None):
        self.values_dir = values_dir
        self.daily_dir = daily_dir
        self.delay = delay
        self.range_days = range_days
        self.crypto_limit = crypto_limit
        self.driver = None
        
        # Manejadores de base de datos con esquema normalizado
        self.influxdb_config = influxdb_config or InfluxDBConfig()
        self.postgres_config = postgres_config or PostgreSQLConfig()
        self.influx_manager = InfluxDBManager(self.influxdb_config)
        self.postgres_manager = PostgreSQLManager(self.postgres_config)
        
        self.setup_driver(headless)
        
        # Crear directorio principal
        os.makedirs(self.daily_dir, exist_ok=True)
    
    def setup_driver(self, headless: bool = True):
        """
        Configura el driver de Chrome con opciones anti-detecci√≥n
        """
        chrome_options = Options()
        
        if headless:
            chrome_options.add_argument("--headless")
        
        # Opciones anti-detecci√≥n
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36")
        
        # Deshabilitar im√°genes para velocidad
        prefs = {
            "profile.managed_default_content_settings.images": 2,
            "profile.default_content_settings.popups": 0,
            "profile.managed_default_content_settings.media_stream": 2
        }
        chrome_options.add_experimental_option("prefs", prefs)
        
        # Anti-detecci√≥n adicional
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        
        try:
            # Usar webdriver-manager para autom√°ticamente descargar ChromeDriver
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # Ejecutar script para ocultar webdriver
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                "userAgent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36'
            })
            logger.info("‚úÖ Driver de Chrome configurado correctamente")
        except Exception as e:
            logger.error(f"‚ùå Error al configurar Chrome driver: {e}")
            logger.error("\nüö® CHROME NO EST√Å INSTALADO üö®")
            logger.error("Instala Chrome en tu sistema:")
            logger.error("Ubuntu/Debian:")
            logger.error("  wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -")
            logger.error("  sudo sh -c 'echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" >> /etc/apt/sources.list.d/google-chrome.list'")
            logger.error("  sudo apt update && sudo apt install google-chrome-stable")
            logger.error("CentOS/RHEL/Fedora:")
            logger.error("  sudo dnf install google-chrome-stable")
            raise
    
    def connect_databases(self):
        """Conectar a PostgreSQL e InfluxDB con esquema normalizado"""
        postgres_connected = False
        influx_connected = False
        
        try:
            postgres_connected = self.postgres_manager.connect()
            if postgres_connected:
                # Mostrar estad√≠sticas iniciales de rangos
                stats = self.postgres_manager.get_coingecko_range_scraping_stats()
                if stats:
                    logger.info("üìä Estado actual scraping rangos CoinGecko:")
                    for status, data in stats.items():
                        logger.info(f"   {status}: {data['count']} cryptos, {data['total_points']} puntos, {data['with_data']} con datos")
        except Exception as e:
            logger.error(f"‚ùå No se pudo conectar a PostgreSQL: {e}")
        
        try:
            influx_connected = self.influx_manager.connect()
        except Exception as e:
            logger.error(f"‚ùå No se pudo conectar a InfluxDB: {e}")
        
        return postgres_connected, influx_connected
    
    def load_cryptocurrencies(self) -> List[Dict]:
        """Carga lista de criptomonedas CoinGecko desde esquema normalizado"""
        try:
            cryptocurrencies = self.postgres_manager.get_coingecko_cryptocurrencies_for_ranges(limit=self.crypto_limit)
            
            if not cryptocurrencies:
                logger.warning("‚ö†Ô∏è No se encontraron criptomonedas CoinGecko en PostgreSQL")
                logger.info("üí° Intentando cargar desde archivo JSON como respaldo...")
                
                # Fallback al archivo JSON si existe
                try:
                    with open("criptomonedas.json", 'r', encoding='utf-8') as f:
                        json_cryptos = json.load(f)
                        # Adaptar formato para esquema normalizado
                        cryptocurrencies = []
                        for crypto in json_cryptos[:self.crypto_limit] if self.crypto_limit else json_cryptos:
                            adapted = {
                                'nombre': crypto.get('nombre', ''),
                                'simbolo': crypto.get('simbolo', ''),
                                'enlace': crypto.get('enlace', ''),
                                'slug': crypto.get('enlace', '').split('/')[-1] if crypto.get('enlace') else '',
                                'scraping_status': 'pending',
                                'priority_category': 'URGENT'
                            }
                            cryptocurrencies.append(adapted)
                        
                        logger.info(f"‚úÖ Cargadas {len(cryptocurrencies)} criptomonedas desde archivo JSON de respaldo")
                except FileNotFoundError:
                    logger.error("‚ùå No se encontr√≥ archivo JSON de respaldo")
                    return []
                except json.JSONDecodeError:
                    logger.error("‚ùå El archivo JSON de respaldo no tiene un formato v√°lido")
                    return []
            
            return cryptocurrencies
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando criptomonedas: {e}")
            return []
    
    def group_dates_into_ranges(self, dates: List[str], range_days: int = None) -> List[Tuple[str, str]]:
        """Agrupa fechas en rangos de N d√≠as"""
        if not dates:
            return []
        
        if range_days is None:
            range_days = self.range_days
        
        sorted_dates = sorted(dates)
        ranges = []
        
        i = 0
        while i < len(sorted_dates):
            start_date = sorted_dates[i]
            
            # Buscar el final del rango (hasta range_days fechas)
            end_index = min(i + range_days - 1, len(sorted_dates) - 1)
            end_date = sorted_dates[end_index]
            
            ranges.append((start_date, end_date))
            i = end_index + 1
        
        return ranges
    
    def get_last_processed_date(self, symbol: str) -> Optional[str]:
        """Obtiene la √∫ltima fecha procesada de una criptomoneda"""
        crypto_data = self.load_crypto_daily_data(symbol)
        return crypto_data.get('last_processed_date')
    
    def filter_pending_dates(self, dates: List[str], last_processed_date: Optional[str]) -> List[str]:
        """Filtra fechas que a√∫n no han sido procesadas"""
        if not last_processed_date:
            return dates
        
        # Continuar desde la siguiente fecha despu√©s de la √∫ltima procesada
        return [date for date in dates if date > last_processed_date]
    
    def get_next_start_date(self, available_dates: List[str], last_processed_date: Optional[str]) -> Optional[str]:
        """Obtiene la siguiente fecha desde donde empezar a procesar"""
        if not last_processed_date:
            return min(available_dates) if available_dates else None
        
        # Buscar la primera fecha disponible despu√©s de la √∫ltima procesada
        sorted_dates = sorted(available_dates)
        for date in sorted_dates:
            if date > last_processed_date:
                return date
        
        return None  # No hay fechas pendientes
    
    def extract_url_name(self, enlace: str) -> str:
        """Extrae el nombre de la URL del enlace"""
        return enlace.rstrip('/').split('/')[-1]
    
    def get_available_dates_from_values(self, symbol: str) -> Set[str]:
        """Obtiene las fechas disponibles del archivo de valores generales con validaci√≥n"""
        try:
            values_file = os.path.join(self.values_dir, f"{symbol}.json")
            if not os.path.exists(values_file):
                logger.warning(f"‚ö†Ô∏è No se encontr√≥ archivo de valores para {symbol}")
                return set()
            
            with open(values_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            dates = set()
            for item in data.get('data', []):
                timestamp = item.get('timestamp')
                if timestamp:
                    try:
                        # ARREGLADO: Validar timestamp antes de conversi√≥n
                        timestamp_num = float(timestamp)
                        # Convertir timestamp a fecha
                        dt = datetime.fromtimestamp(timestamp_num / 1000)
                        date_str = dt.strftime('%Y-%m-%d')
                        dates.add(date_str)
                    except (ValueError, TypeError, OSError):
                        logger.debug(f"‚ö†Ô∏è Timestamp inv√°lido para {symbol}: {timestamp}")
                        continue
            
            logger.info(f"üìÖ Encontradas {len(dates)} fechas √∫nicas para {symbol}")
            return dates
            
        except Exception as e:
            logger.error(f"‚ùå Error leyendo fechas de {symbol}: {e}")
            return set()
    
    def timestamp_for_date(self, date_str: str, is_end: bool = False) -> int:
        """Convierte fecha string a timestamp Unix con validaci√≥n"""
        try:
            dt = datetime.strptime(date_str, '%Y-%m-%d')
            if is_end:
                # Final del d√≠a (23:59:59)
                dt = dt.replace(hour=23, minute=59, second=59)
            else:
                # Inicio del d√≠a (00:00:00)
                dt = dt.replace(hour=0, minute=0, second=0)
            
            return int(dt.timestamp())
        except Exception as e:
            logger.error(f"‚ùå Error convirtiendo fecha {date_str}: {e}")
            return 0
    
    def get_crypto_file_path(self, symbol: str) -> str:
        """Obtiene la ruta del archivo consolidado de una criptomoneda"""
        return os.path.join(self.daily_dir, f"{symbol}_daily_data.json")
    
    def load_crypto_daily_data(self, symbol: str) -> Dict:
        """Carga los datos existentes de una criptomoneda"""
        filepath = self.get_crypto_file_path(symbol)
        try:
            if os.path.exists(filepath):
                with open(filepath, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {
                'symbol': symbol,
                'created_at': datetime.now().isoformat(),
                'last_updated': datetime.now().isoformat(),
                'last_processed_date': None,
                'data': []
            }
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error cargando datos de {symbol}: {e}")
            return {
                'symbol': symbol,
                'created_at': datetime.now().isoformat(),
                'last_updated': datetime.now().isoformat(),
                'last_processed_date': None,
                'data': []
            }
    
    def save_crypto_daily_data(self, symbol: str, crypto_data: Dict) -> bool:
        """Guarda los datos consolidados de una criptomoneda"""
        filepath = self.get_crypto_file_path(symbol)
        try:
            crypto_data['last_updated'] = datetime.now().isoformat()
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(crypto_data, f, indent=2, ensure_ascii=False)
            
            return True
        except Exception as e:
            logger.error(f"‚ùå Error guardando datos consolidados de {symbol}: {e}")
            return False
    
    def combine_range_data(self, price_data: List, market_cap_data: List) -> List[Dict]:
        """Combina datos de precios y capitalizaci√≥n por timestamp para un rango con validaciones robustas"""
        combined_data = []
        
        # ARREGLADO: Convertir market_cap_data a diccionario con validaci√≥n
        market_cap_dict = {}
        if market_cap_data:
            for item in market_cap_data:
                try:
                    if len(item) >= 2 and item[0] is not None:
                        timestamp = int(float(item[0]))  # Validar antes de convertir
                        market_cap_dict[timestamp] = item[1]
                except (ValueError, TypeError, IndexError):
                    continue  # Saltar items inv√°lidos
        
        # ARREGLADO: Procesar datos de precios con validaci√≥n
        if price_data:
            for price_item in price_data:
                try:
                    if len(price_item) >= 2 and price_item[0] is not None:
                        timestamp = int(float(price_item[0]))  # Validar antes de convertir
                        price = price_item[1]
                        market_cap = market_cap_dict.get(timestamp, None)
                        
                        # Solo a√±adir si tenemos datos v√°lidos
                        if price is not None or market_cap is not None:
                            combined_data.append({
                                'timestamp': timestamp,
                                'price': price,
                                'market_cap': market_cap
                            })
                except (ValueError, TypeError, IndexError):
                    continue  # Saltar items inv√°lidos
        
        logger.info(f"‚úÖ Combinados {len(combined_data)} puntos de datos v√°lidos para rango")
        return combined_data
    
    def add_range_data_to_crypto(self, symbol: str, end_date: str, combined_data: List[Dict]) -> bool:
        """A√±ade datos de rango al archivo consolidado de una criptomoneda"""
        try:
            # Cargar datos existentes
            crypto_data = self.load_crypto_daily_data(symbol)
            
            # A√±adir nuevos datos a la lista existente
            crypto_data['data'].extend(combined_data)
            
            # Actualizar la √∫ltima fecha procesada con el final del rango
            crypto_data['last_processed_date'] = end_date
            crypto_data['last_updated'] = datetime.now().isoformat()
            
            # Ordenar datos por timestamp para mantener orden cronol√≥gico
            crypto_data['data'].sort(key=lambda x: x.get('timestamp', 0))
            
            # Guardar archivo consolidado
            if self.save_crypto_daily_data(symbol, crypto_data):
                logger.debug(f"üìÅ Respaldo JSON actualizado para {symbol} (hasta {end_date})")
                return True
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error a√±adiendo datos de rango de {symbol} (hasta {end_date}): {e}")
            return False
    
    def download_range_data_selenium(self, url_name: str, start_date: str, end_date: str, data_type: str) -> Optional[List]:
        """Descarga datos para un rango de fechas usando Selenium con validaci√≥n de timestamps"""
        timestamp_from = self.timestamp_for_date(start_date)
        timestamp_to = self.timestamp_for_date(end_date, True)
        
        if timestamp_from == 0 or timestamp_to == 0:
            logger.error(f"‚ùå Timestamps inv√°lidos para {url_name} - {start_date} a {end_date}")
            return None
        
        url = f"https://www.coingecko.com/{data_type}/{url_name}/usd/custom.json?from={timestamp_from}&to={timestamp_to}"
        
        try:
            logger.info(f"üîÑ Descargando {data_type} para {url_name} - {start_date} a {end_date}")
            logger.debug(f"URL: {url}")
            
            # Navegar a la URL
            self.driver.get(url)
            
            # Esperar a que se cargue el contenido JSON
            wait = WebDriverWait(self.driver, 15)
            
            # Buscar el elemento <pre> que contiene el JSON
            try:
                json_element = wait.until(
                    EC.presence_of_element_located((By.TAG_NAME, "pre"))
                )
                json_text = json_element.text
            except TimeoutException:
                # Si no hay elemento <pre>, intentar obtener el texto completo de la p√°gina
                try:
                    body_element = self.driver.find_element(By.TAG_NAME, "body")
                    json_text = body_element.text
                except Exception:
                    logger.error(f"‚ùå No se pudo encontrar contenido JSON para {url_name} - {start_date} a {end_date}")
                    return None
            
            # Verificar si hay contenido
            if not json_text.strip():
                logger.warning(f"‚ö†Ô∏è Respuesta vac√≠a para {url_name} - {start_date} a {end_date} ({data_type})")
                return None
            
            # Parsear el JSON
            try:
                data = json.loads(json_text)
                stats = data.get('stats', [])
                
                logger.info(f"‚úÖ {len(stats)} registros para {url_name} - {start_date} a {end_date} ({data_type})")
                return stats
                
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Error al parsear JSON para {url_name} - {start_date} a {end_date} ({data_type}): {e}")
                logger.debug(f"Contenido recibido: {json_text[:500]}...")
                return None
                
        except TimeoutException:
            logger.error(f"‚ùå Timeout al cargar datos para {url_name} - {start_date} a {end_date} ({data_type})")
            return None
        except WebDriverException as e:
            logger.error(f"‚ùå Error de WebDriver para {url_name} - {start_date} a {end_date} ({data_type}): {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Error inesperado para {url_name} - {start_date} a {end_date} ({data_type}): {e}")
            return None
    
    def random_delay(self, min_delay: float = None, max_delay: float = None):
        """Delay aleatorio entre peticiones"""
        if min_delay is None:
            min_delay = self.delay
        if max_delay is None:
            max_delay = self.delay * 1.5
        
        delay = random.uniform(min_delay, max_delay)
        time.sleep(delay)
    
    def process_cryptocurrency_ranges_normalized(self, crypto: Dict) -> Dict:
        """Procesa una criptomoneda por rangos usando esquema normalizado con todas las correcciones"""
        symbol = crypto.get('simbolo', '').upper()
        enlace = crypto.get('enlace', '')
        nombre = crypto.get('nombre', '')
        priority_category = crypto.get('priority_category', 'UNKNOWN')
        current_status = crypto.get('scraping_status', 'pending')
        crypto_id = crypto.get('crypto_id')  # IMPORTANTE: Obtener crypto_id
        
        if not symbol or not enlace:
            logger.warning(f"‚ö†Ô∏è Datos incompletos para {nombre}")
            return {'symbol': symbol, 'success': 0, 'failed': 0, 'skipped': 0}
        
        logger.info(f"\nüìä Procesando rangos {nombre} ({symbol}) - Prioridad: {priority_category}")
        logger.info(f"üîÑ Estado actual: {current_status} | ID: {crypto_id}")
        
        start_time = time.time()
        
        # ARREGLADO: Marcar como en progreso usando crypto_id
        self.postgres_manager.update_coingecko_range_scraping_status(
            crypto_id=crypto_id, symbol=symbol, name=nombre, status='in_progress',
            notes=f'Iniciando descarga de rangos (prioridad: {priority_category})'
        )
        
        # Extraer nombre de URL
        url_name = self.extract_url_name(enlace)
        logger.info(f"üîç URL name: {url_name}")
        
        # Obtener fechas disponibles del archivo general
        available_dates = self.get_available_dates_from_values(symbol)
        if not available_dates:
            logger.warning(f"‚ö†Ô∏è No hay fechas disponibles para {symbol}")
            self.postgres_manager.update_coingecko_range_scraping_status(
                crypto_id=crypto_id, symbol=symbol, name=nombre, status='error',
                notes='No se encontraron fechas disponibles en archivo de valores'
            )
            return {'symbol': symbol, 'success': 0, 'failed': 0, 'skipped': 0}
        
        # Verificar √∫ltima fecha procesada y determinar desde d√≥nde continuar
        last_processed = self.get_last_processed_date(symbol)
        sorted_dates = sorted(list(available_dates))
        
        if last_processed:
            logger.info(f"üìÖ √öltima fecha procesada: {last_processed}")
            
            # Obtener la siguiente fecha desde donde continuar
            next_start_date = self.get_next_start_date(sorted_dates, last_processed)
            
            if not next_start_date:
                logger.info(f"‚úÖ {symbol} est√° completamente actualizado (hasta {last_processed})")
                self.postgres_manager.update_coingecko_range_scraping_status(
                    crypto_id=crypto_id, symbol=symbol, name=nombre, status='completed',
                    last_date=last_processed,
                    notes='Crypto completamente actualizada - no hay fechas pendientes'
                )
                return {'symbol': symbol, 'success': 0, 'failed': 0, 'skipped': len(available_dates)}
            
            # Filtrar fechas pendientes
            pending_dates = self.filter_pending_dates(sorted_dates, last_processed)
            logger.info(f"üîÑ Continuando desde {next_start_date}")
            logger.info(f"üìÖ Fechas pendientes: {len(pending_dates)} (de {next_start_date} a {max(pending_dates)})")
        else:
            pending_dates = sorted_dates
            logger.info(f"üÜï Primera ejecuci√≥n - procesando todas las fechas")
            logger.info(f"üìÖ Total de fechas: {len(pending_dates)} (de {min(pending_dates)} a {max(pending_dates)})")
        
        if not pending_dates:
            logger.info(f"‚úÖ No hay fechas nuevas para procesar en {symbol}")
            self.postgres_manager.update_coingecko_range_scraping_status(
                crypto_id=crypto_id, symbol=symbol, name=nombre, status='completed',
                last_date=last_processed,
                notes='No hay fechas pendientes para procesar'
            )
            return {'symbol': symbol, 'success': 0, 'failed': 0, 'skipped': len(available_dates)}
        
        # Agrupar fechas en rangos
        date_ranges = self.group_dates_into_ranges(pending_dates, self.range_days)
        logger.info(f"üì¶ Agrupado en {len(date_ranges)} rangos de hasta {self.range_days} d√≠as cada uno")
        
        success_count = 0
        failed_count = 0
        skipped_count = 0
        total_points_saved = 0
        
        for i, (start_date, end_date) in enumerate(date_ranges, 1):
            range_start_time = time.time()
            
            try:
                logger.info(f"üì¶ [{i}/{len(date_ranges)}] Rango {symbol}: {start_date} ‚Üí {end_date}")
                
                # Descargar datos de precios para el rango
                price_data = self.download_range_data_selenium(url_name, start_date, end_date, 'price_charts')
                if not price_data:
                    logger.error(f"‚ùå No se pudieron obtener datos de precios para {symbol} - {start_date} a {end_date}")
                    failed_count += 1
                    
                    # Log de error para este rango
                    if crypto_id:
                        range_duration = int(time.time() - range_start_time)
                        self.postgres_manager.create_range_scraping_log_entry(
                            crypto_id, False, start_date, end_date, 0,
                            'Error obteniendo datos de precios', range_duration
                        )
                    continue
                
                # Delay entre peticiones
                self.random_delay()
                
                # Descargar datos de capitalizaci√≥n de mercado para el rango
                market_cap_data = self.download_range_data_selenium(url_name, start_date, end_date, 'market_cap')
                if not market_cap_data:
                    logger.warning(f"‚ö†Ô∏è No se pudieron obtener datos de capitalizaci√≥n para {symbol} - {start_date} a {end_date}")
                    market_cap_data = []
                
                # Combinar datos
                combined_data = self.combine_range_data(price_data, market_cap_data)
                
                if combined_data:
                    # Guardar en InfluxDB con esquema normalizado
                    influx_success = False
                    if self.influx_manager.write_api:
                        influx_success = self.influx_manager.save_coingecko_range_data(
                            crypto, start_date, end_date, combined_data
                        )
                    
                    # Guardar respaldo JSON
                    backup_success = self.add_range_data_to_crypto(symbol, end_date, combined_data)
                    
                    range_duration = int(time.time() - range_start_time)
                    
                    if influx_success or backup_success:
                        success_count += 1
                        total_points_saved += len(combined_data)
                        logger.info(f"‚úÖ Rango completado: {symbol} hasta {end_date} ({len(combined_data)} puntos)")
                        
                        # ARREGLADO: Actualizar progreso usando crypto_id
                        self.postgres_manager.update_coingecko_range_scraping_status(
                            crypto_id=crypto_id, symbol=symbol, name=nombre,
                            status='in_progress', last_date=end_date, total_points=len(combined_data),
                            notes=f'Procesando rango {i}/{len(date_ranges)}: {start_date} ‚Üí {end_date}'
                        )
                        
                        # Log de √©xito para este rango
                        if crypto_id:
                            self.postgres_manager.create_range_scraping_log_entry(
                                crypto_id, True, start_date, end_date, len(combined_data),
                                None, range_duration
                            )
                    else:
                        failed_count += 1
                        logger.error(f"‚ùå Error guardando datos de {symbol} - {start_date} a {end_date}")
                        
                        # Log de error para este rango
                        if crypto_id:
                            self.postgres_manager.create_range_scraping_log_entry(
                                crypto_id, False, start_date, end_date, 0,
                                'Error guardando datos combinados', range_duration
                            )
                else:
                    failed_count += 1
                    logger.error(f"‚ùå No se generaron datos combinados para {symbol} - {start_date} a {end_date}")
                    
                    # Log de error para este rango
                    if crypto_id:
                        range_duration = int(time.time() - range_start_time)
                        self.postgres_manager.create_range_scraping_log_entry(
                            crypto_id, False, start_date, end_date, 0,
                            'No se generaron datos combinados', range_duration
                        )
                
                # Delay entre rangos
                self.random_delay()
                
            except Exception as e:
                logger.error(f"‚ùå Error procesando {symbol} - {start_date} a {end_date}: {e}")
                failed_count += 1
                
                # Log de error para este rango
                if crypto_id:
                    range_duration = int(time.time() - range_start_time)
                    self.postgres_manager.create_range_scraping_log_entry(
                        crypto_id, False, start_date, end_date, 0,
                        f'Error procesando rango: {str(e)[:200]}', range_duration
                    )
        
        # ARREGLADO: Actualizar estado final usando crypto_id
        if failed_count == 0 and success_count > 0:
            final_date = max(pending_dates) if pending_dates else last_processed
            self.postgres_manager.update_coingecko_range_scraping_status(
                crypto_id=crypto_id, symbol=symbol, name=nombre,
                status='completed', last_date=final_date, total_points=total_points_saved,
                notes=f'Descarga completada exitosamente. {success_count} rangos procesados, {total_points_saved} puntos totales'
            )
        elif success_count > 0:
            final_date = max([end for _, end in date_ranges[:success_count]]) if success_count > 0 else last_processed
            self.postgres_manager.update_coingecko_range_scraping_status(
                crypto_id=crypto_id, symbol=symbol, name=nombre,
                status='error', last_date=final_date, total_points=total_points_saved,
                notes=f'Descarga parcial. {success_count} rangos exitosos, {failed_count} fallidos'
            )
        else:
            self.postgres_manager.update_coingecko_range_scraping_status(
                crypto_id=crypto_id, symbol=symbol, name=nombre,
                status='error', last_date=last_processed, total_points=0,
                notes=f'Descarga fall√≥ completamente. {failed_count} rangos fallidos'
            )
        
        return {
            'symbol': symbol,
            'success': success_count,
            'failed': failed_count,
            'skipped': skipped_count,
            'total_points': total_points_saved
        }
    
    def run(self) -> None:
        """Ejecuta el proceso completo de rangos con esquema normalizado"""
        
        logger.info(f"üöÄ Iniciando descarga por rangos CoinGecko (esquema normalizado FINAL)")
        
        # Conectar a bases de datos
        postgres_connected, influx_connected = self.connect_databases()
        
        if not postgres_connected:
            logger.error("‚ùå No se pudo conectar a PostgreSQL - Proceso abortado")
            return
        
        if influx_connected:
            logger.info("‚úÖ InfluxDB conectado - Los datos se guardar√°n en InfluxDB")
        else:
            logger.warning("‚ö†Ô∏è InfluxDB no disponible - Solo se guardar√°n respaldos JSON y estados en PostgreSQL")
        
        # Cargar criptomonedas CoinGecko desde esquema normalizado
        cryptocurrencies = self.load_cryptocurrencies()
        
        if not cryptocurrencies:
            logger.error("‚ùå No se encontraron criptomonedas CoinGecko para procesar")
            return
        
        logger.info(f"üìä Procesando {len(cryptocurrencies)} criptomonedas CoinGecko desde esquema normalizado")
        if self.crypto_limit:
            logger.info(f"üî¢ L√≠mite aplicado: {self.crypto_limit} criptomonedas")
        
        logger.info(f"üì¶ Tama√±o de rango: {self.range_days} d√≠as por rango")
        logger.info(f"üìÅ Los archivos de respaldo se guardar√°n en: {os.path.abspath(self.daily_dir)}")
        
        total_stats = {
            'processed': 0,
            'total_success': 0,
            'total_failed': 0,
            'total_skipped': 0,
            'total_points': 0
        }
        
        try:
            for i, crypto in enumerate(cryptocurrencies, 1):
                priority = crypto.get('priority_category', 'UNKNOWN')
                status = crypto.get('scraping_status', 'unknown')
                
                logger.info(f"\n[{i}/{len(cryptocurrencies)}] {priority} | {status} ======================")
                
                try:
                    # Decidir si procesar seg√∫n prioridad
                    if priority == 'CURRENT' and status == 'completed':
                        logger.info(f"‚è≠Ô∏è Saltando {crypto.get('simbolo')} - Ya est√° actualizado")
                        total_stats['total_skipped'] += 1
                        continue
                    
                    result = self.process_cryptocurrency_ranges_normalized(crypto)
                    
                    total_stats['processed'] += 1
                    total_stats['total_success'] += result['success']
                    total_stats['total_failed'] += result['failed']
                    total_stats['total_skipped'] += result['skipped']
                    total_stats['total_points'] += result.get('total_points', 0)
                    
                    logger.info(f"Resultado {result['symbol']}: ‚úÖ{result['success']} ‚ùå{result['failed']} ‚è≠Ô∏è{result['skipped']} üìä{result.get('total_points', 0)}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error procesando {crypto.get('nombre', 'Desconocido')}: {e}")
                    total_stats['total_failed'] += 1
                
                # Pausa entre criptomonedas
                if i < len(cryptocurrencies):
                    self.random_delay(self.delay * 2, self.delay * 3)
                    
        except KeyboardInterrupt:
            logger.info("\nüõë Proceso interrumpido por el usuario")
        except Exception as e:
            logger.error(f"‚ùå Error inesperado durante el procesamiento: {e}")
        
        logger.info(f"\n\nüìà === RESUMEN FINAL ===")
        logger.info(f"üî¢ Criptomonedas procesadas: {total_stats['processed']}")
        logger.info(f"‚úÖ Rangos exitosos: {total_stats['total_success']}")
        logger.info(f"‚ùå Rangos fallidos: {total_stats['total_failed']}")
        logger.info(f"‚è≠Ô∏è Rangos saltados: {total_stats['total_skipped']}")
        logger.info(f"üìä Total de puntos guardados: {total_stats['total_points']}")
        logger.info(f"üìä Estados actualizados en PostgreSQL (esquema normalizado)")
        
        if influx_connected:
            logger.info(f"üíæ Datos hist√≥ricos guardados en InfluxDB (bucket: {self.influxdb_config.database})")
        
        logger.info(f"üìÅ Respaldos JSON en: {os.path.abspath(self.daily_dir)}")
        
        # Mostrar estad√≠sticas finales usando esquema normalizado
        final_stats = self.postgres_manager.get_coingecko_range_scraping_stats()
        if final_stats:
            logger.info(f"\nüìä === ESTADO FINAL RANGOS COINGECKO ===")
            for status, data in final_stats.items():
                logger.info(f"{status}: {data['count']} cryptos, {data['total_points']} puntos, {data['with_data']} con datos")
    
    def close(self):
        """Cierra el driver y conexiones"""
        if self.driver:
            self.driver.quit()
            logger.info("üîê Driver cerrado")
        
        if self.influx_manager:
            self.influx_manager.close()
        
        if self.postgres_manager:
            self.postgres_manager.close()


def main():
    """Funci√≥n principal"""
    scraper = None
    
    try:
        print("üöÄ === Descargador de Rangos CoinGecko (VERSI√ìN FINAL NORMALIZADA) ===")
        print("TODAS LAS CORRECCIONES APLICADAS:")
        print("‚úÖ Esquema normalizado con separaci√≥n por fuentes")
        print("‚úÖ Manejo robusto de valores None en conversiones")
        print("‚úÖ Identificaci√≥n √∫nica por crypto_id (sin duplicados)")
        print("‚úÖ Validaciones mejoradas de datos de entrada")
        print("‚úÖ Logs detallados y tracking completo")
        print("Formato: [{timestamp, price, market_cap}, ...] con tracking de progreso")
        print("Instalando dependencias:")
        print("pip install selenium webdriver-manager influxdb-client psycopg2-binary")
        print("ChromeDriver se descarga autom√°ticamente\n")
        
        # Cargar variables de entorno
        load_env_file()
        
        # Configuraci√≥n
        headless = input("¬øEjecutar en modo headless? (s/N): ").lower().startswith('s')
        delay = float(input("Delay entre peticiones en segundos (recomendado: 2-4): ") or "2.5")
        range_days = int(input("D√≠as por rango (recomendado: 30): ") or "30")
        
        # L√≠mite de criptomonedas (opcional)
        limit_input = input("¬øL√≠mite de criptomonedas a procesar? (Enter para todas): ").strip()
        crypto_limit = int(limit_input) if limit_input.isdigit() else None
        
        # Crear configuraciones
        try:
            postgres_config = PostgreSQLConfig()
        except Exception as e:
            logger.error(f"‚ùå Error en configuraci√≥n de PostgreSQL: {e}")
            return
        
        try:
            influxdb_config = InfluxDBConfig()
        except ValueError as e:
            logger.error(f"‚ùå Error en configuraci√≥n de InfluxDB: {e}")
            logger.info("Continuando solo con PostgreSQL y respaldos JSON...")
            influxdb_config = None
        
        # Crear scraper
        scraper = SeleniumRangeCryptoDataScraper(
            values_dir="values",
            daily_dir="daily_data",
            delay=delay,
            headless=headless,
            range_days=range_days,
            crypto_limit=crypto_limit,
            influxdb_config=influxdb_config,
            postgres_config=postgres_config
        )
        
        # Ejecutar scraping
        scraper.run()
        
    except KeyboardInterrupt:
        print("\nüõë Proceso interrumpido por el usuario")
    except Exception as e:
        logger.error(f"‚ùå Error en main: {e}")
    finally:
        if scraper:
            scraper.close()


if __name__ == "__main__":
    main()